-----------------------------
Current project architecture:|
-----------------------------
High-Level Architecture
- In my current project, we are running a microservices-based application on AWS. Each microservice is 
  containerized using Docker and deployed on Amazon EKS (Kubernetes). We use Helm charts for packaging 
  and managing Kubernetes manifests, and ArgoCD for GitOps-based continuous delivery.
- Networking: We use an AWS ALB Ingress Controller to expose services securely with HTTPS and route 
  traffic based on host/path rules.
- Storage & Databases: The application uses Amazon RDS for relational data and Amazon S3 for object 
  storage. For caching, we rely on Amazon ElastiCache (Redis).
- CI/CD: Our pipeline is built with Jenkins integrated with SonarQube for code quality, Trivy for image 
  scanning, and finally pushing images to Amazon ECR before deploying to EKS via ArgoCD.
- Monitoring & Logging: We use Prometheus + Grafana for metrics, ELK/EFK stack for centralized logging, 
  and CloudWatch for AWS resource-level monitoring.
- Secrets & Config: Secrets are managed in AWS Secrets Manager and referenced in Terraform and Kubernetes.
- Infrastructure as Code: All infrastructure (VPC, EKS, RDS, S3, IAM roles, etc.) is provisioned and 
  managed with Terraform.

------------------------
My Role in the Project:|
------------------------
- As a DevOps Engineer, my role includes:
- Designing and maintaining the CI/CD pipeline (Jenkins + GitOps with ArgoCD).
- Implementing Terraform modules for multi-environment provisioning (dev/stage/prod).
- Setting up and maintaining Kubernetes deployments, network policies, and Helm charts.
- Ensuring security best practices by integrating vulnerability scanning (Trivy, SonarQube, 
  IAM least-privilege policies).
- Implementing S3 lifecycle policies and cost optimization strategies.
- Handling Kubernetes troubleshooting ‚Äî e.g., stuck pods, scaling issues, and network policy debugging.
- Setting up Prometheus alerts and Grafana dashboards for performance and availability monitoring.
- Collaborating with developers to optimize application performance and reduce deployment failures.
- Managing drift detection in Terraform and enforcing infra consistency via CI/CD."*

----
GIT:|
----
We follow a GitFlow branching model with main, develop, feature, release, and hotfix branches. 
All new features were developed in feature branches, merged into develop after review, then promoted
through release branches to main for production. 
Hotfixes were patched directly from main and merged back. 
CI/CD pipelines were tied to develop (staging) and main (production).

main ‚Üí stable production code.
develop ‚Üí integration branch for staging/UAT.
feature/ ‚Üí short-lived branches for new features.
release/ ‚Üí prepares production release (bug fixes only).
hotfix/ ‚Üí urgent production fixes, merged into both main and develop.

***flow diagram showing how a new feature reaches production***

üü† feature/ ‚Üí üü¢ develop ‚Üí üü£ release ‚Üí üîµ main ‚Üí üî¥ Production

So, production (live) always comes from main, not directly from develop.

1) main branch
- Always stable, production-ready code.
- Deployments to production are triggered from here.

2) develop branch
- integration branch where features are merged after passing code review + CI tests.
- Acts as staging area for QA/UAT deployments.

3) feature/* branches
- Developers create feature branches from develop
- Example: feature/user-authentication
- Merged back into develop via Pull Request (with code review + automated tests)

4) release/* branch
- when a release is planned, we cut a branch from develop
- QA/UAT testing happens from here
- only bug fixes are allowed; no new features
- Example: release/v1.3

5) hotfix/* branch
- For urgent production issues
- created from main branch, tested then merged into both main and develop
- Example: hotfix/payment-bug

üîë ‚ú® ùóñùó¢ùó†ùó†ùó¢ùó° ùóöùóúùóß ùóßùóòùó•ùó†ùó¶ (ùó†ùóîùóóùóò ùó¶ùóúùó†ùó£ùóüùóò) ‚ú®
üìÇ ùó•ùó≤ùóΩùóºùòÄùó∂ùòÅùóºùóøùòÜ (ùó•ùó≤ùóΩùóº): A storage space for your project (like a folder with history).
 üíæ ùóñùóºùó∫ùó∫ùó∂ùòÅ: A snapshot of your code ‚Üí like ‚ÄúSave Game‚Äù in coding.
 üåø ùóïùóøùóÆùóªùó∞ùóµ: A safe workspace to try new features without touching the main code.
 ‚¨áÔ∏è ùó£ùòÇùóπùóπ: Bring the latest changes from GitHub to your laptop.
 ‚¨ÜÔ∏è ùó£ùòÇùòÄùóµ: Send your commits from your laptop to GitHub.
 üîÄ ùó£ùòÇùóπùóπ ùó•ùó≤ùóæùòÇùó≤ùòÄùòÅ (ùó£ùó•): A request to merge your branch ‚Üí teammates review this.
 ü§ù ùó†ùó≤ùóøùó¥ùó≤: Combine changes from one branch into another.
 üìú ùó•ùó≤ùóØùóÆùòÄùó≤: Replay your commits on top of another branch to keep history clean.
 ‚ö° ùóñùóºùóªùó≥ùóπùó∂ùó∞ùòÅ: When two people edit the same line ‚Üí Git asks you to choose.
 ‚è™ ùó•ùó≤ùòÄùó≤ùòÅ: Undo commits locally (before pushing).
 ‚Ü©Ô∏è ùó•ùó≤ùòÉùó≤ùóøùòÅ: Undo commits already pushed (safe for shared branches).
 üìå ùó¶ùòÅùóÆùòÄùóµ: Temporarily save unfinished work without committing.
 üßπ ùó¶ùóæùòÇùóÆùòÄùóµ: Combine multiple commits into one clean commit.
 üçí ùóñùóµùó≤ùóøùóøùòÜ-ùóΩùó∂ùó∞ùó∏: Take one specific commit from another branch without merging everything.

üéì ùóòùó´ùóîùó†ùó£ùóüùóò: ùóñùó¢ùóüùóüùóòùóöùóò ùó£ùó•ùó¢ùóùùóòùóñùóß ùó™ùó¢ùó•ùóû
üìÇ ùó•ùó≤ùóΩùóº: The project folder where the whole team stores work.
 üíæ ùóñùóºùó∫ùó∫ùó∂ùòÅ: ‚ÄúAdded Introduction section.‚Äù
 üåø ùóïùóøùóÆùóªùó∞ùóµ: Create your own copy ‚Üí main project remains safe.
 ‚¨áÔ∏è ùó£ùòÇùóπùóπ: Get teammates‚Äô updates before writing.
 ‚¨ÜÔ∏è ùó£ùòÇùòÄùóµ: Upload your finished part to the shared folder.
 üîÄ ùó£ùó• (Pull Request): Ask, ‚ÄúCan we add my part to the main project?‚Äù
 ü§ù ùó†ùó≤ùóøùó¥ùó≤: Team approves ‚Üí your part gets added.
 üìú ùó•ùó≤ùóØùóÆùòÄùó≤: Rewrite your work on top of the latest version neatly.
 ‚ö° ùóñùóºùóªùó≥ùóπùó∂ùó∞ùòÅ: Two members wrote on the same line ‚Üí decide which one to keep. 
 ‚è™ ùó•ùó≤ùòÄùó≤ùòÅ: Undo your last change locally.
 ‚Ü©Ô∏è ùó•ùó≤ùòÉùó≤ùóøùòÅ: Cancel a wrong change in the shared folder.
 üìå ùó¶ùòÅùóÆùòÄùóµ: Pause unfinished work without finalizing.
 üßπ ùó¶ùóæùòÇùóÆùòÄùóµ: Combine small edits into one neat update.
 üçí ùóñùóµùó≤ùóøùóøùòÜ-ùóΩùó∂ùó∞ùó∏: Copy one good line from a friend‚Äôs section.

-------
 LINUX |
-------
1) Soft link vs Hard link?
-   A hard link is like an alternate name for the same file, sharing the same inode, while a soft link 
  is more like a shortcut pointing to the file path. The key difference is: if the original is deleted, 
  hard links still keep the data, but soft links break.‚Äù


----------
TERRAFORM |
----------
1) what is terraform state?
- Terraform state is a file that keeps track of the resources Terraform manages, including metadata
  and current configuration.For security and collaboration, state should be stored remotely in a backend
  like S3 with encryption and locking enabled, and access should be controlled using IAM policies. This 
  ensures sensitive data is protected & multiple team members can safely work on the same infrastructure.

2) Difference between `terraform plan` and `terraform apply`.
- terraform plan lets you preview the changes. It will make without touching any real infrastructure,
  which helps avoid mistakes. terraform apply actually makes the changes and updates the state to match
  the desired configuration. Typically, we run plan first to review, and then apply to execute safely.

3) How do you manage secrets in Terraform?
- In Terraform,manage secrets by keeping them out of code. use sensitive variables, environment variables,
  or fetch secrets from services like AWS Secrets Manager or Vault. I also ensure Terraform state is
  stored securely in encrypted backends to prevent exposure.Hardcoding secrets is strictly avoided.

4) What are Terraform providers? Can you create a custom one?
- Terraform providers are plugins that allow Terraform to communicate with external services and manage 
  resources. For example, the AWS provider lets Terraform create, update, and delete AWS resources like S3 
  buckets, EC2 instances, and RDS databases by mapping Terraform resources to AWS API calls.

  Yes, you can create a custom provider if a service is not supported by existing providers. Custom 
  providers are typically written in Go using the Terraform Plugin SDK. You define the provider, its 
  resources, and CRUD operations.

5) what is the role of terraform init
- Terraform init is the first command you run in a new or existing Terraform directory. It sets up the 
  working directory by downloading required providers, initializing backend state, fetching modules, and 
  preparing Terraform to execute plans or apply changes. Without init, Terraform cannot interact with the 
  cloud provider or manage resources.

6) How do `count`, `for_each`, and `dynamic` blocks work in Terraform?
-> Refer notes for example of each
- count lets you create multiple identical resources using a numeric index.
- for_each is more flexible, allowing multiple resources based on a map or set, giving custom keys 
  for each resource.
- dynamic blocks let you programmatically generate nested blocks, useful when the number or content of 
  sub-blocks depends on variables or lists.

7) what are provisioners and What is the difference between local-exec and remote-exec provisioners? 
- Provisioners are used in Terraform to run scripts or commands after resource creation. 
- local-exec runs commands on the machine executing Terraform
- remote-exec runs commands on the created resource itself via SSH or WinRM. 
---> Local-exec is useful for local automation or notifications, whereas remote-exec is used for configuring
  servers or installing software on remote instances.

8) How do you perform Terraform state locking in a team environment?
- In a team environment, Terraform state locking prevents multiple engineers from modifying the state
  simultaneously, which could cause corruption. We achieve this by using remote backends like S3 with 
  DynamoDB for locking or Terraform Cloud, which automatically handles locks. This ensures safe, 
  coordinated infrastructure changes across teams.

9) What is `terraform import` used for? Any limitations? 
-> Refer notes for sample script
- Terraform import is used to bring existing infrastructure under Terraform management by updating the 
  state file. It allows Terraform to track and manage resources created outside of Terraform. However, 
  import only updates the state; it does not generate Terraform configuration automatically, handles one
  resource at a time, and may require careful handling of dependencies.

10) How do you manage multiple environments (dev/stage/prod) in Terraform?
- I manage multiple environments in Terraform using a modular approach. I keep reusable infrastructure 
  logic in modules (like VPC, EC2, RDS), and then reference these modules in environment-specific
  directories (dev, stage, prod).
- Each environment has its own tfvars file with unique parameters (like instance size, CIDR ranges, or 
  scaling configs). This ensures consistency across environments while still allowing flexibility.
- Additionally, I configure a separate remote backend (e.g., S3 + DynamoDB) per environment to keep 
  state isolated and avoid conflicts. This way, teams can deploy independently without risk of overwriting
  another environment‚Äôs state.

11) Explain the difference between `depends_on` and implicit dependency.
- Terraform automatically creates implicit dependencies when one resource references another. 
  For example, if a subnet uses a VPC ID, Terraform knows the VPC must be created first.
- However, sometimes there is no direct reference but still a required order. In that case, we use 
  depends_on to explicitly define the dependency.
- I usually prefer implicit dependencies because they keep code clean, but I use depends_on in special 
  cases ‚Äî like when running provisioners, creating null resources, or when a resource has a hidden 
  dependency not visible in attributes.

12) What are the best practices for writing reusable Terraform modules?
- When writing reusable Terraform modules, I follow best practices such as keeping modules small and 
  focused, using input variables for flexibility, and exposing useful outputs. I also enforce version
  pinning, provide clear documentation, and validate code with terraform validate and tflint.
- I structure modules with main.tf, variables.tf, and outputs.tf for clarity, and always design them to 
  support multiple environments (dev/stage/prod). This ensures consistency, reusability & maintainability
  across projects.

13) Can two Terraform modules reference the same remote backend?
- 

14) How do you handle Terraform drifts?
- Terraform drift occurs when infra changes outside of Terraform. I usually detect drift by running 
  terraform plan, which compares the real infra with the state file. In CI/CD, I automate drift detection
  so unexpected changes are caught early.
- To handle drift, I either reapply Terraform to restore the desired state or, if the manual change was
  intentional, update the Terraform code accordingly. In some cases, I use terraform import or state 
  manipulation to bring Terraform in sync. I also follow best practices like limiting manual console
  changes, enabling drift detection in Terraform Cloud, and enforcing IaC through pipelines.
- To prevent drift, I enforce restricted IAM permissions, use Terraform Cloud‚Äôs drift detection, and 
  promote strict Infrastructure-as-Code practices

15) How do you integrate Terraform into a CI/CD pipeline?
- I integrate Terraform into CI/CD pipelines by automating all stages of infrastructure provisioning. 
  The pipeline checks out code, runs terraform fmt and validate, then terraform init to connect to a
  remote backend. Next, it executes terraform plan and outputs the plan for review. For production, a 
  manual approval stage is included. Finally, the pipeline runs terraform apply to provision or update
  resources.

16) What‚Äôs the difference between `terraform taint` and `terraform destroy`?
- terraform taint is used when a resource is unhealthy or misconfigured; it marks the resource for
  replacement. On the next terraform apply, Terraform will destroy and recreate only that resource while
  leaving others untouched.
- terraform destroy, on the other hand, immediately destroys all resources in the current state 
  (or targeted resources if -target is used). It's usually used to tear down an environment entirely.

17) Describe a real-world issue you faced with Terraform and how you resolved it.
- In production, I‚Äôve faced several Terraform challenges. One time, a resource block was accidentally
  removed, which could have deleted an S3 bucket. I used terraform plan to verify, reverted the change,
  and applied safely. Another time, multiple engineers were using local state, causing corruption; 
  migrating to a remote backend with locking resolved it. I‚Äôve also handled provider version conflicts 
  during Terraform upgrades by testing in dev, updating required providers, and validating all modules 
  before production deployment. These experiences taught me the importance of state management, CI/CD
  safety checks, and controlled testing before production changes.

18) conditions in terraform
- In a multi-environment setup, I used ternary expressions and count-based resource creation to provision
  larger EC2s in production, skip S3 buckets in dev, and dynamically add security group rules only when 
  required. This reduced code duplication and made modules reusable across environments.
--> instance_type = var.environment == "prod" ? "t3.micro" : "t3.small"


-------
DOCKER:|
-------
ADD vs COPY
====
COPY is a straightforward instruction used for copying files and directories from the 
local build context to a specified destination within the Docker image.
syntax:
COPY <src> <dest>

ADD can perform the same file and directory copying as COPY, but it also includes enhanced features.
syntax:
ADD <src> <dest>
Key difference:
COPY = simple file copy
ADD = copy + optional auto-extract + URL download

------------
KUBERNETES:|
------------
Q) What is a Pod in Kubernetes, and how is it used?
-  A Pod in Kubernetes is the smallest deployable unit that encapsulates one or more containers.Containers
   in a Pod share the same network namespace and storage volumes, making it easy for them to communicate
   and work together. Typically, we use single-container Pods, but in cases where multiple tightly coupled
   containers need to run together‚Äîlike a main application and a sidecar‚Äîthey are placed in the same Pod.
   Pods are usually not created directly; instead, we use higher-level controllers like Deployments or 
   StatefulSets to manage them for scaling and self-healing.

Q) Explain each major component of Kubernetes and its role.
-  Kubernetes is made up of control plane components and worker node components.
   The control plane includes the API Server, which is the main entry point; 
   etcd, which stores cluster state; 
   the Scheduler, which decides where Pods run; 
   and the Controller Manager, which ensures the desired state of resources.

   On worker nodes, we have kubelet, which runs containers, 
   kube-proxy for networking, 
   and a container runtime like containerd. 
   Additionally, add-ons like CoreDNS, Ingress Controller, and Metrics Server provide service discovery,
   traffic management, & monitoring. Together, these components allow k8s to orchestrate containers at scale.

Q) Deployment vs StatefulSet vs DaemonSet
-  Deployments are for stateless apps with identical Pods, 
   StatefulSets are for stateful apps needing stable identities and persistent storage, and 
   DaemonSets ensure one Pod runs on every node ‚Äî typically for monitoring, logging, or security.

1) during an upgrade, how does k8s know that which pods are older and newer version and recreate them
- Kubernetes knows which pods are older or newer by looking at the pod-template-hash label 
  (derived from the pod spec in the Deployment). 
  Each Deployment revision has a unique hash ‚Üí old ReplicaSet vs new ReplicaSet. T
  The Deployment controller then replaces old pods with new ones in a controlled manner.

2) How do you expose a Kubernetes application to external traffic?
- In Kubernetes, we can expose applications externally in multiple ways. For simple testing, we use 
  NodePort which opens a fixed port on every node. In cloud environments, we typically use a LoadBalancer
  Service that provisions a cloud LB like AWS ELB or GCP LB. For more advanced scenarios, we use Ingress
  with an Ingress Controller like NGINX or AWS ALB, which allows us to manage routing, TLS termination,
  and host/path-based traffic rules. In my current projects, we prefer Ingress for production workloads 
  since it provides flexibility, security, and scalability.

3) What is the difference between Deployment and StatefulSet in Kubernetes?
- A Deployment is used for stateless applications where Pods are interchangeable, like web servers or APIs.
  Pods don‚Äôt need stable identities or storage, and scaling is fast. 
- A StatefulSet, on the other hand, is used for stateful workloads like databases, where each Pod needs a
 stable identity, persistent storage, and ordered scaling. 
- For example, in my projects, we deploy microservices using Deployments, while for MongoDB clusters or 
  Kafka brokers, we rely on StatefulSets to maintain data consistency and pod identity.

4) What is a ConfigMap, and how is it different from a Secret?
-  A ConfigMap is used to store non-sensitive configuration data like environment names or feature flags.
-  while a Secret is specifically designed for sensitive information like passwords, API tokens, and 
   certificates. 
-  The key difference is that ConfigMaps store data in plain text, whereas Secrets are base64 encoded and
   can be encrypted with KMS. In practice, I use ConfigMaps for application configs and Secrets for 
   database credentials or TLS certificates, ensuring strict RBAC access.

5) how do you perform secrets rotation in kubernetes?
-  In Kubernetes, I avoid hardcoding static secrets and instead integrate with an external secrets manager
   like AWS Secrets Manager or HashiCorp Vault. 
-  I use the External Secrets Operator or the Secrets Store CSI driver to sync secrets into Kubernetes.
   This allows credentials such as database passwords to rotate automatically, while the application picks
   them up without manual intervention. 
-  For TLS certs, I rely on cert-manager for automatic renewal. This way, secret rotation is automated, 
   secure, and downtime-free.

6) what is headless service?
-  A Headless Service is a Kubernetes Service without a ClusterIP. It doesn‚Äôt load-balance traffic but 
   instead exposes the Pod IPs directly. We use it with StatefulSets or databases like Cassandra or Kafka
   where each Pod needs a stable identity and direct communication with peers. In my project, a Headless
   Service allowed our Cassandra cluster Pods to discover each other and maintain the stateful cluster.

7) What is persistent volume and persistent volume claim?
-  A PersistentVolume (PV) is a piece of storage in the cluster, provisioned by an admin or dynamically 
   via StorageClass.
-  A PersistentVolumeClaim (PVC) is a user or application‚Äôs request for storage. Kubernetes binds a PVC 
   to a matching PV, allowing Pods to use persistent storage independently of Pod lifecycle.

8) What if there are multiple PVCs and a single PV?
-  A PV can only bind to one PVC at a time (unless it supports ReadWriteMany).
   Kubernetes will match based on size and access mode.

9) CrashLoopBackOff error?
-  CrashLoopBackOff happens when a container keeps crashing after startup. 
-  To troubleshoot, I first check kubectl get pods for restart count, 
   then inspect logs using kubectl logs (including --previous for earlier attempts). 
-  Next, I describe the Pod (kubectl describe pod) to check events, image issues, mount errors, 
   or probe failures. 
-  I verify environment variables, ConfigMaps, secrets, and resource limits, and sometimes test the 
   container locally to isolate application-level problems. 
-  Finally, I adjust liveness/readiness probes or fix misconfigurations before redeploying.

10) What does OOMKilled mean, and what are the possible causes?
-  OOMKilled means the container was terminated by the kernel because it exceeded its memory limit. 
-  Common causes include insufficient memory limits, memory leaks in the application, processing large 
   data payloads, or improper JVM/application memory configuration. 
-  To fix it, I check the Pod description and logs, adjust memory requests/limits, monitor memory usage,
   and optimize the application to prevent excessive memory consumption.

11) ErrImagePull / ImagePullBackOff?
-  ErrImagePull occurs when Kubernetes fails to pull a container image, usually due to an incorrect image
   name, tag, missing image in registry, or missing credentials for a private registry. 
-  ImagePullBackOff happens when Kubernetes retries pulling the image multiple times and is backing off. 
-  To troubleshoot, I describe the Pod (kubectl describe pod <pod>), verify the image name/tag, ensure 
   network access, and configure imagePullSecrets if using a private registry.

12) How can you add a Secret in a particular YAML file? 
-  To add a Secret in k8s, you first define it as a Secret resource in YAML with base64-encoded values. 
   Then, in the Pod YAML, you can either reference it as environment variables using 
   env.valueFrom.secretKeyRef or mount it as a volume. 
   This allows containers to securely access sensitive data without hardcoding credentials in the Pod spec.

13) Explain RoleBinding and ClusterRoleBinding.
-  RoleBindings are namespaced and grant a Role or ClusterRole within that namespace. 
-  ClusterRoleBindings are cluster-scoped and grant a ClusterRole across all namespaces and cluster 
   resources. 
-  Use RoleBinding for per-namespace least-privilege access (e.g., an app‚Äôs SA in dev), and 
   ClusterRoleBinding for cluster-wide needs (operators, org-wide viewer roles).

14) Deployment strategies?
-  6 key deployment strategies ‚¨áÔ∏è
   1Ô∏è‚É£ Recreate ‚Äì Simple but comes with downtime
   2Ô∏è‚É£ Rolling Update ‚Äì Gradual shift, no downtime
   3Ô∏è‚É£ Shadow ‚Äì Test new versions silently in production
   4Ô∏è‚É£ Canary ‚Äì Release to a small percentage first
   5Ô∏è‚É£ Blue-Green ‚Äì Two environments, zero downtime
   6Ô∏è‚É£ A/B Testing ‚Äì Compare user response to different versions

-----
AWS:|
-----
1) Your EC2 instance in a private subnet needs to download packages without a NAT Gateway. 
   What alternatives exist?
-  If an EC2 in a private subnet needs to download packages without a NAT Gateway, I have several 
   alternatives. The preferred method is to use VPC endpoints, such as an S3 Gateway endpoint, so the 
   instance can securely fetch packages stored in S3. Another option is to pre-download packages into S3
   or a private repository accessible via VPC endpoints. If VPC endpoints aren‚Äôt sufficient, we can deploy
   a proxy EC2 in a public subnet to route traffic, or use SSM Run Commands and Systems Manager to install
   packages without direct internet access. These approaches avoid NAT GW costs while maintaining security.

2) How would you set up geolocation-based routing using AWS services?
-  To implement geolocation-based routing in AWS, I deploy the application in multiple regions and use 
   Route 53 with a Geolocation Routing Policy. Each DNS record is associated with a continent, country,
   or region, and requests from users are routed to the closest endpoint. I also set up a default record
   to handle unmatched locations. For production, I combine this with Route 53 health checks to ensure
   failover if a regional endpoint is down, and optionally integrate with CloudFront for global caching 
   and improved latency.

3) What is a Pre-signed URL?
-  A Pre-signed URL is a temporary,secure link that gives time-limited access to an object in an S3 bucket.
-  Generated by someone who already has permission to access the object (via IAM role/user).
-  Useful for sharing private objects without making the bucket public.

4) different S3 bucket policies
-  Public Read-Only Access
-  Restrict Access to Specific IAM Users or Roles
-  Restrict Access by IP Address
-  Enforce Encryption (SSE-S3 or SSE-KMS)
-  Cross-Account Access
-  Restrict Access to VPC Endpoint
-  Logging Bucket Policy (for ELB/CloudTrail logs)

5) What are S3 access points?
-  Instead of using the bucket URL directly, you create different access points.
-  Each access point has its own name, URL, and access policy.
-  This makes it easier to manage who can access what inside a big bucket.

6) 


---------
GENERAL:|
---------

1) A developer accidentally pushed sensitive AWS credentials into the public GitHub repository. 
   What immediate actions would you take?
-  If a developer accidentally pushed AWS credentials to a public GitHub repository, my first action would
   be to immediately revoke or rotate the exposed credentials to prevent misuse. 
-  Next, I would remove the secrets from the Git history using tools like BFG Repo Cleaner and force-push
   the cleaned repository. 
-  I would audit CloudTrail logs to check for any suspicious activity and rotate any dependent credentials
   if necessary. 
-  Finally, I would implement preventive measures such as using Secrets Manager, pre-commit hooks, and 
   scanning tools to avoid future incidents.

2) 

Interview questions by
--  Sudheer Medaramettla
