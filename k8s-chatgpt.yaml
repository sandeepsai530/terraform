#what is pod?
#“A Pod is the smallest deployable unit in Kubernetes. It wraps one or more containers that need to run 
#together. For example, in one project I ran a Java app container along with a Fluentd sidecar inside the
#same pod to handle logs. Unlike VMs, pods are lightweight and disposable.”

#what is replicaset?
#“A ReplicaSet makes sure a specified number of pod replicas are always running. In practice, I rarely 
#create it directly since Deployments manage ReplicaSets automatically. For instance, when I scaled a 
#Deployment from 2 to 4 replicas, Kubernetes created a new ReplicaSet in the background.”

#what is RBAC?
#“RBAC controls what users and service accounts can do in Kubernetes. For instance, I gave the Jenkins 
#service account only deployment permissions in the dev namespace, so it couldn’t accidentally delete 
#cluster-wide resources. It’s all about enforcing least privilege.”

#what is node?
#“A Node is a worker machine that runs pods. In EKS, it’s basically an EC2 instance. For example, I 
#labeled GPU nodes in one project, and then used node selectors so ML workloads would only run on those
#GPU nodes.”

#what is CRD?
#“A CRD extends Kubernetes with new resource types. For example, ArgoCD defines an Application CRD to 
#manage GitOps deployments. I’ve worked with CRDs when installing operators like Istio or Prometheus — 
#they make Kubernetes extensible beyond built-in resources.”


# ------------------------
# Namespace
# ------------------------
#“A Namespace is a logical grouping of resources. I used them to separate dev, QA, and prod environments
#within the same cluster. Namespaces also make it easier to apply RBAC and quotas per environment.”
apiVersion: v1
kind: Namespace
metadata:
  name: demo-namespace

---
# ------------------------
# ResourceQuota (per-namespace limits)
# ------------------------
#“A ResourceQuota sets overall limits for a namespace, while LimitRange sets per-pod or per-container 
#limits. For example, I applied a quota in the dev namespace to restrict it to 10 pods and 4 CPUs total, 
#and a LimitRange so each pod must request at least 100Mi of memory. This prevents resource abuse.”

apiVersion: v1
kind: ResourceQuota
metadata:
  name: demo-namespace-quota
  namespace: demo-namespace
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    limits.cpu: "4"
    limits.memory: 8Gi
    pods: "20"
    services: "10"

---
# ------------------------
# LimitRange (default per-pod/container requests & limits)
# ------------------------
apiVersion: v1
kind: LimitRange
metadata:
  name: demo-limit-range
  namespace: demo-namespace
spec:
  limits:
    - type: Container
      default:
        cpu: "500m"
        memory: "512Mi"
      defaultRequest:
        cpu: "200m"
        memory: "256Mi"

---
# ------------------------
# ServiceAccount
# ------------------------
#“A ServiceAccount in Kubernetes provides an identity for pods or processes to interact with the k8s API.
#Unlike a user account, it’s meant for workloads, not humans.”
#“For example, when I set up Jenkins pipelines to deploy apps on EKS, I created a ServiceAccount with 
#RBAC permissions limited to deployments and services. Jenkins pods then used that ServiceAccount to apply
#manifests securely.”

apiVersion: v1
kind: ServiceAccount
metadata:
  name: demo-sa
  namespace: demo-namespace

---
# ------------------------
# Role
# ------------------------
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: demo-role
  namespace: demo-namespace
rules:
  - apiGroups: [""]
    resources: ["pods", "services"]
    verbs: ["get", "list", "watch"]

---
# ------------------------
# RoleBinding
# ------------------------
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: demo-rolebinding
  namespace: demo-namespace
subjects:
  - kind: ServiceAccount
    name: demo-sa
    namespace: demo-namespace
roleRef:
  kind: Role
  name: demo-role
  apiGroup: rbac.authorization.k8s.io

---
#------------------------
# StorageClass
#------------------------
#“A StorageClass defines how storage is provisioned dynamically. For example, I created a StorageClass in
# EKS that uses AWS gp3 volumes. Whenever a PVC was created, Kubernetes automatically provisioned an EBS
# volume — no manual PV needed.”

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3-storage
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  fsType: ext4
  encrypted: "true"
  iops: "3000"     # Optional: Customize IOPS
  throughput: "125" # Optional: Customize throughput (MB/s)
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer


---
# ------------------------
# PersistentVolume
# ------------------------
apiVersion: v1
kind: PersistentVolume
metadata:
  name: demo-pv
spec:
  capacity:
    storage: 5Gi
  accessModes: ["ReadWriteOnce"]
  hostPath:
    path: /data/demo

---
# ------------------------
# PersistentVolumeClaim
# ------------------------
#“A PersistentVolume represents storage in the cluster, and a PersistentVolumeClaim is a request by a pod
# to use that storage. For instance, in one project I created a PVC of 20Gi for a MySQL StatefulSet, which
# Kubernetes dynamically provisioned as an AWS EBS volume.”

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: demo-pvc
  namespace: demo-namespace
spec:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 1Gi

---
# ------------------------
# Deployment
# ------------------------
##“A Deployment manages a set of identical pods, ensuring the desired number of replicas are running. In a
#recent project, I used a Deployment to run 3 replicas of a web app, allowing for rolling updates with 
#zero downtime. If a pod crashes, the Deployment automatically creates a new one.”

apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-deployment
  namespace: demo-namespace
spec:
  replicas: 2
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      serviceAccountName: demo-sa
      containers:
        - name: demo-app
          image: nginx:latest
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: "200m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"

---
# ------------------------
# StatefulSet
# ------------------------
#“StatefulSet is like a Deployment but used for stateful apps that need persistent storage and stable 
#identity, like databases. For example, in one project I deployed Kafka using StatefulSet so each broker
#had a fixed hostname and its own PVC. Unlike Deployment, StatefulSet pods scale in order and don’t get 
#random names.”

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: demo-db
  namespace: demo-namespace
spec:
  serviceName: demo-db-headless
  replicas: 2
  selector:
    matchLabels:
      app: demo-db
  template:
    metadata:
      labels:
        app: demo-db
    spec:
      containers:
        - name: db
          image: mysql:5.7
          env:
            - name: MYSQL_ROOT_PASSWORD
              value: rootpass
          volumeMounts:
            - name: db-storage
              mountPath: /var/lib/mysql
  volumeClaimTemplates:
    - metadata:
        name: db-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 2Gi

---
# ------------------------
# Headless Service (for StatefulSet)
# ------------------------
apiVersion: v1
kind: Service
metadata:
  name: demo-db-headless
  namespace: demo-namespace
spec:
  clusterIP: None
  selector:
    app: demo-db
  ports:
    - port: 3306

---
# ------------------------
# PodDisruptionBudget (for StatefulSet)
# ------------------------
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: demo-db-pdb
  namespace: demo-namespace
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: demo-db

---
# ------------------------
# DaemonSet
# ------------------------
#“A DaemonSet ensures that a copy of a pod runs on every node in the cluster. I used this for deploying 
#Prometheus Node Exporter so that every node could expose system metrics. The nice part is when a new node
#joins, the DaemonSet automatically schedules the pod there.”

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: demo-daemon
  namespace: demo-namespace
spec:
  selector:
    matchLabels:
      app: demo-daemon
  template:
    metadata:
      labels:
        app: demo-daemon
    spec:
      containers:
        - name: log-agent
          image: busybox
          command: ["sh", "-c", "while true; do echo logging; sleep 10; done"]

---
# ------------------------
# Job
# ------------------------
#“A Job is used to run pods until a task completes successfully. For example, I set up a Job to run a 
#one-time database migration script during an upgrade. Unlike Deployments, Jobs don’t keep pods running 
#forever — they exit after completion.”

apiVersion: batch/v1
kind: Job
metadata:
  name: demo-job
  namespace: demo-namespace
spec:
  template:
    spec:
      containers:
        - name: job
          image: busybox
          command: ["echo", "Hello from Job!"]
      restartPolicy: Never
  backoffLimit: 3

---
# ------------------------
# CronJob
# ------------------------
#“A CronJob runs Jobs on a time schedule, just like Linux cron. In my last project, I used a CronJob to
# trigger nightly database backups at midnight. If a pod fails, Kubernetes retries it on the next schedule.”

apiVersion: batch/v1
kind: CronJob
metadata:
  name: demo-cronjob
  namespace: demo-namespace
spec:
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cron
              image: busybox
              command: ["echo", "Hello from CronJob!"]
          restartPolicy: OnFailure

---
# ------------------------
# Service
# ------------------------
#“A Service exposes pods and gives them a stable network endpoint. For example, I used a ClusterIP service
# for internal microservices and a LoadBalancer service to expose my frontend to the internet via AWS ELB.
# Unlike pods, Services don’t change IPs, so they decouple consumers from pod lifecycles.”

apiVersion: v1
kind: Service
metadata:
  name: demo-service
  namespace: demo-namespace
spec:
  type: ClusterIP
  selector:
    app: demo
  ports:
    - port: 80
      targetPort: 80

---
# ------------------------
# Ingress
# ------------------------
#“An Ingress provides HTTP/HTTPS routing into the cluster. For example, in one project we used NGINX 
#Ingress Controller to expose shop.example.com to the frontend service and api.example.com to the backend
#service, all behind a single load balancer. It also handled SSL termination.”

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: demo-ingress
  namespace: demo-namespace
spec:
  rules:
    - host: demo.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: demo-service
                port:
                  number: 80

---
# ------------------------
# NetworkPolicy
# ------------------------
#“A NetworkPolicy defines which pods can communicate with each other. For example, I restricted access so
#only frontend pods could talk to backend pods, and everything else was denied. This gave us a 
#zero-trust model inside the cluster.”

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: demo-network-policy
  namespace: demo-namespace
spec:
  podSelector:
    matchLabels:
      app: demo
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app: demo-db
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: demo-db

---
# ------------------------
# HorizontalPodAutoscaler
# ------------------------
#“HPA automatically scales the number of pods based on CPU, memory, or custom metrics. In one of my 
#projects, our frontend pods scaled from 3 to 12 during peak traffic. Once load dropped, HPA scaled them
#back down, saving costs.”

#“VPA automatically adjusts CPU and memory requests/limits for pods. I used it for a backend service where
# traffic was unpredictable — it increased memory during spikes, then tuned it down to save resources.
# Unlike HPA, VPA changes resource size, not replica count.”


apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: demo-hpa
  namespace: demo-namespace
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: demo-deployment
  minReplicas: 2
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70

---
# ------------------------
# Advanced Pod Scheduling (affinity, tolerations, nodeSelector)
# ------------------------
apiVersion: v1
kind: Pod
metadata:
  name: demo-scheduling-pod
  namespace: demo-namespace
spec:
  nodeSelector:
    disktype: ssd
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - demo
          topologyKey: "kubernetes.io/hostname"
  tolerations:
    - key: "dedicated"
      operator: "Equal"
      value: "gpu"
      effect: "NoSchedule"
  containers:
    - name: nginx
      image: nginx

---
# ------------------------
# ConfigMap
# ------------------------
#“A ConfigMap is used to inject non-sensitive configuration into pods. For example, I stored environment
# variables like APP_ENV=prod and mounted them into my application container. This way, I could reuse the
# same image across dev, QA, and prod with different configs.”

apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-config
  namespace: demo-namespace
data:
  APP_COLOR: blue
  APP_MODE: production

---
# ------------------------
# Secret
# ------------------------
#“A Secret is similar to a ConfigMap but is meant for sensitive data like passwords or API keys. For
# example, I stored the database credentials in a Secret and mounted them as environment variables in my
# backend pods. In production, I integrate Secrets with AWS Secrets Manager for extra security.”

apiVersion: v1
kind: Secret
metadata:
  name: demo-secret
  namespace: demo-namespace
type: Opaque
data:
  DB_USER: ZGVtb3VzZXI=   # base64 for "demouser"
  DB_PASS: ZGVtb3Bhc3M=   # base64 for "demopass"

---
# ------------------------
# Pod with InitContainer using ConfigMap & Secret
# ------------------------
apiVersion: v1
kind: Pod
metadata:
  name: demo-init-pod
  namespace: demo-namespace
spec:
  initContainers:
    - name: init-demo
      image: busybox
      command: ['sh', '-c', 'echo "Initializing with $APP_COLOR mode=$APP_MODE"']
      envFrom:
        - configMapRef:
            name: demo-config
  containers:
    - name: app
      image: nginx
      env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: demo-secret
              key: DB_USER
        - name: DB_PASS
          valueFrom:
            secretKeyRef:
              name: demo-secret
              key: DB_PASS
      ports:
        - containerPort: 80

# Pods
# Deployments
# ReplicaSet
# StatefulSet
# DaemonSet
# Jobs
# CronJob
# ConfigMap & Secrets
# PV & PVCs
# StorageClass
# Services
# Ingress
# Network policies
# RBAC
# Resource Quotas & Limit Ranges
# Pod Security Admission
# Namespaces
# Nodes
# HPA & VPA & Cluster Autoscaler
# Custom Resource Definitions
