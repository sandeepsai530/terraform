Linux:
du vs df

connect via ssh - ssh -i ~/downloads/vpn.pem ec2-user@ip-address

Topics to cover:
- why terraform? advantages
terraform commands:
terraform init - Initializes working directory(downloads required files like provider), its first cmd.
terraform plan - shows what changes terraform will make without applyig them.
terraform validate - checks whether the cnfiguration is syntactically valid. Terraform validate is included in terraform apply
terraform apply - Applies the changes to your infra. will prompt for approvals unless -auto-approve used.
terraform destroy - Tears down all resources defined in the current configuration.
terraform fmt - Formats .tf files to the canonical style.

.gitignore - files that not needed to be tracked by git can be placed under .gitignore folder

variables:
-----------
syntax:
variable "<variable-name>" {
  type = ""
  default= ""
}

number,string,bool,map,list
Number of ways variables can be defined:
    - variables.tf 
    - terraform.tfvars
    - Inline with CLI (terraform apply -var="instance_type=t2.small")
    - ENV variables (export TF_VAR_instance_type=t2.medium)
    - command prompt
    - modules
    - Locals
      Ex: locals {
            app_name = "${var.project}-${var.environment}"
          }

  prefernce of variables:
  - command line (-var="instance_type=t2.small")
  - tfvars
  - env var
  - default values
  - user prompt/command prompt

if declared as below the n variable is considered as mandatory
variable "sg_id" {
}

if declared as below the n variable is considered as optional
variable "tags" {
  default = {}
}


- conditions -> expression ? "true-value : "false-value"
  Example: instance_type = var.Environment == "prod" ? "t2.medium" : "t2.micro"

- loops -> count based, for each, dynamic blocks
- functions - max, length, split, merge, join, lower, upper, file
** learn split vs join functions
- data sources -> query existing information
  Example:
  data "aws_ami" "joindevops" {
  most_recent = true
  owners = ["973714476881"]

  filter {
    name = "name"
    values = ["RHEL-9-DevOps-Practice"]
  }
}

- output
- locals -> store expressions in a variable
  Example:
  locals {
  ami_id = data.aws_ami.joindevops.id
}
- state and remote state with locking
- provisioners -> local-exec and remote-exec
- multiple environments -> tfvars

#conditions in terraform
please refer session-27 in joindevops
variable "instance_type" {
  default = "t2.micro" 
  validation {
    condition = contains(["t3.micro", "t3.small", "t3.medium"], var.instance_type)
    error_message = "valid values for instance type are: t3.small/t3.micro/t3.medium"
  }
}

Data sources:
-------------
-> data sources are used to query existing information from the provider
-> data sources in terraform are used to get information about resources external to terraform and uses them to set up your terraform resources.

types variables that we can pass:
1. command line -> -var "<instance_type=t2.micro" or -var "<var-name>=<var-value>"
2. tfvars
3. env var
4. default values
5. user prompt

conditions:
if else, when

if(expression) {
  this statement runs if expression is true
}
else {
  this statement runs if expression is false
}

expression ? "this runs if true" : "this runs if false"
example:  instance_type = var.environment == "prod" ? "t3.small" : "t2.micro"

loops:
1. count based loops
2. for each loops
3. dynamic blocks

Count vs for-each:
count - when you need N identical resources.
for-each: when you have a collection of named or uniquely configured resources.
    When you want more control or to create resources based on a map or set of values, you use for_each.
    access each item using each.key and each.value.
    useful for creating multiple similar resources without repeating code.

interpolation: concating two variables with text

Output blocks: These are used to print the information. it will be used in module develeopment too.

locals:
-------
Locals are used to run expressions or functions and save the results to variables. refer below
session-25: 19mins
Example:
locals {
  ami_id = data.aws_ami.joindevops.id
}

LOCALS vs VARIABLES:
--------------------
locals are used to store expressions, it can even store simple key value pairs just like variables.
variables can't store expressions. variables can't refer other variable. locals can refer other locals or variables.
variables can be overriden. locals can't be overriden. 
Example for locals:
locals {
  instance_type = "t3.micro"
}

instance_type = local.instance_type

Example for variables:
variable "instance_type" {
  default = "t3.micro"
}

instance_type=var.instance_type

State Management:
-----------------
declared/desired infra -> .tf files. whatever user write in tf files, that is what user wants.
actual infra -> what terraform is creating in provider.

desired infra == actual infra

terraform.tfstate -> it is a file terraform creates to know what it is created. this is actual infra created by terraform.

someone changed the name of ec2 manually inside console.
terraform plan or apply
terraform reads state file and then compare that with actual infra using provider.

if you update tf files...
terraform.tfstate -> expense-dev-backend
compared with tf files -> expense-dev-backend-changed

if you update few parameters, resources will not be created again it will just update
but few parameters if you update, we are forced to recreate resources.

tfstate is very important file, we need to secure it.

clone terraform repo -> terraform apply
duplicate resources or errors

in collaboration environment we must maintain state file remotely.
locking is important, so that we can prevent parallel execution.

Dynamic blocks:
---------------
loops are used to create multiple resources.
dynamic blocks are used to create multiple blocks inside a resource.

Loops:
------
1-count based loops: use it to iterate lists
2-for each loop: use it to iterate maps
3-dynamic blocks:

provisioners:
-------------
provisioners are used to take some action either locally or remote when terraform created servers
Creation time:
By default, provisioners run when the resource they are defined within is created.
provisioners are only run during creation, not during update or anyother lifecycle.

destroy time:
if when = destroy is specified, the provisioner will run when the resource is defined within is destroyed
By default it takes when = creation time if nothing was mentioned
2 type of provisioners:
1-local-exec
2-remote-exec

we can use provisoners either creation time or destroy time.

local -> where terraform command is running that is local
remote -> inside the server created by terraform

when = destroy # terraform remote provisioners can be used either while creating or destroying.
# if nothing was mentioned then it will consider to eexcute the provisioner during the execution.

multiple environemnts using terraform:
--------------------------------------
1.tfvars -> used to override default values
2.workspaces
3.seperate codebase - maintain different repos for different environment.

its better to use seperate codebase as other two ways create confusion while creating the resources.

Disadvantages of tfvars/workspaces:
should be very careful, because same code to prod also, any mistake in dev causes confusion in prod.
should have full expertise, too much testing.

Advantages:
code reuse

Disadvantages with seperate codebase:
multiple repos to manage
we may be multiple employees
Code reuse can be achieved with the help of modules.

terraform modules:
variables, functions, ansible roles, locals.

modules: it is like functions, you can pass inputs you will get infra.

** In terraform modules, if you need to access variables then that has to be given in outputs.tf then it can be accessible.



DEV and PROD, remote state use

expense-dev-mysql -> mysql-dev.saisandeep-devops.xyz
expense-dev-backend -> backend-dev.saisandeep-devops.xyz
expense-dev-frontend -> frontend-dev.saisandeep-devops.xyz

expense-prod-mysql -> mysql-prod.saisandeep-devops.xyz
expense-prod-backend -> backend-prod.saisandeep-devops.xyz
expense-prod-frontend -> frontend-prod.saisandeep-devops.xyz

expense-dev or expense-prod

using TFVARS:
-------------
terraform init -reconfigure -backend-config=dev/backend.tf  --> for dev
terraform plan -var-file=dev/dev.tfvars
terraform apply -var-file=dev/dev.tfvars
terraform destroy -var-file=dev/dev.tfvars

terraform init -reconfigure -backend-config=prod/backend.tf  --> for prod
terraform plan -var-file=dev/dev.tfvars
terraform apply -var-file=prod/prod.tfvars
terraform destroy -var-file=prod/prod.tfvars

NAT Gateway:
If you want to enable egress internet to the servers in private subnet, you should create NAT gateway in
public subnet and provide route to private subnets
NAT gateway is for out going traffic

Bastion host:
when you try to connect private servers like backend and database, we need to use bastion host.
Bastion host is a secure, publicly accessible server that acts as a gateway for accessing private 
resources like EC2 instances inside a private subnet of a VPC.

Load Balancer:
ALB -> Listener -> Evaluate rules -> target group -> server

open source modules:
Advantages:
- we dont need to write code

Disadvantages:
- we are dependent on them
- whenever they update, we are forced to update

organisation module:
- we have to write complete code

Advantages:
- fully our control

DB vs RDS:
----------
DB:
- DB installation
- DB upgrades
- DB backups
- DB changes
- DB cluster setup
- DB restoration test

RDS:
- DB installation -> we just need to provide configuration
- DB upgrades - simple clicks
- DB snapshots
- DB cluster -> we can configure replication controllers, high available, storage scalable

what is null resource?
- it will not create any new resource, it is used to connect to the instances, copy the scripts, execute the scripts through provisioners. it has a trigger attribute to take actions when something is changed like instance id.

***OSI model:
----------
Application layer
Presentation layer
session layer
transport layer
network layer
data link layer
physical layer

-> when you hit www.google.com , what happens in the background?
Application layer:
------------------
application layer hits www.google.com - http/https
presentation - encryption
session - session, cookie details
NOTE: three layers together can be called as application layer

transport layer:
----------------
transport - port number
destination port - 80/443/8080/22
source port - system randomly allocates one port to get the resposne - ephemeral port
range: 32768-65535

Network layer:
--------------
Network - IP address
destination IP address - DNS resoultion
SourceIP - server IP address (private IP)
Source IP, source port, destination IP, destination port, data -> packet

Data link -> Mac address
source  mac - laptop mac address
destination mac - router mac address 
frame -> data pack and mac address

physical layer - ethernet, wifi

--------------------------------------------------------------------------------------
Docker vs VirtualMachines

Docker commands:
----------------
docker images
docker ps 
docker ps -a 
docker pull
docker create
docker start
docker rm 
docker exec -it <container-id> bash
docker logs <container-id>
docker inspect <container-id>
docker inspect <image-id>
docker login -u <username>
docker ps -a --no-trunc
docker build -t arg :1.0.0 --progress=plain . -> this provides complete output


**docker pull + docker create + docker start = docker run
docker run -d <image-name> -> images runs in the background as detached mode 
**docker run -d -p 80:80 nginx - > docker run -d -p <hostport>:<containerport> nginx
**host port is managed by us but container port is fixed

what is dockerfile?
It is used to create our custom images using instructions provided by docker.

CMD vs Entrypoint:
------------------
- CMD instructions can be overriden
- you cant override entrypoint -> ping google.com ping facebook.com. If you try to override     ENTRYPOINT it will not override, but it will append.
- For best results we can use CMD and ENTRYPOINT together.
- we can mention command in ENTRYPOINT, default options/inputs can be supplied through CMD. user can always override default options.
- only one CMD and one ENTRYPOINT should be used in Dockerfile.
@16:00 session-44 for better practical explanation.

USER -> set the user of container
WORKDIR -> set the working directory of container/image

ARG vs ENV:
-----------
- ENV variables can be accessed at the image building and in container also.
- ARG variables are only accessed inside image build, not in container.
- ARG can be the first instruction only to provide the version for base image. It cant be useful after FROM instruction.
@55:00 session-44 for detailed explanation

docker volumes:
---------------
session-46 @30:52

docker maintains the images as layers, each and every instruction is one layer. docker creates
1. intermediate container from instruction-1
2. docker runs 2nd instruction on top of IC-1. then docker saves this another layer.
3. docker saves this container as another image layer. create intermediate container out of it IC-2
4. now docker runs 3rd instruction in IC-2 container. docker saves this as another layer.
5. docker creates intermediate container from this layer as IC-3
Refer: session-47 @25:00

How do you optimise docker layers?
----------------------------------
1. less number of layers fater the builds, bcos number of intermediate containers are less.
    you can club multiple instructions into single instruction.
2. keep the frequently chnaging instructions at the bottom of Dockerfile.

Multi-stage builds:
-------------------
for example: Java
JDK - Java Development Kit
JRE - Java Runtime Environment

JDK > JRE
JRE is subset of JDK 

JDK = JRE + extra libraries

while installing some libraries, OS adds extra space to HD. we will take only that jar file output and copy it another Dockerfile where only jre runs.

we can have 2 dockerfiles one is for builder, we can copy the output from builder into 2nd dockerfile and run it, we can save some image space using this.

docker multi stage builds are primarily used to create smaller, more optimized images by seperating the build environment from the runtime environment. we can have one as builder and one as runner, copy the backend output from builder to runner. docker removes builder automatically.

what if underlying docker server crashes?
- we need to maintain multiple docker hosts. you need some orchestrator to manage all the docker hosts. docker swarm is the native orchestrator.

eksctl vs kubectl:
------------------
eksctl used for cluster creation , manage and delete.
kubectl used for interacting with cluster and pushing manifests.
aws configure used to setup your AWS CLI credentials and default settings.

alias ka="kubectl apply -f"

purpose of service:
loadbalancing and pod to pod communication through service
- ClusterIP: default, only works internally
- Nodeport: external requests
- LoadBalancer: only works with cloud providers. here service open classic LB.
LoadBalancer > NodePort > ClusterIP

NameSpace: 
- A Namespace in Kubernetes is a way to divide cluster resources between multiple users or teams.
- It helps organize and isolate resources like Pods, Services, and Deployments.
- Useful for multi-tenant environments, CI/CD pipelines, and managing resource quotas.
- it takes default namespace if nothing mentioned

Pod:
Pod is the smallest deplyable unit in k8. Pod can have multiple containers 1 or many.
multi-containers are useful in few applications like shipping logs through sidecar containers.

Static pods:
these are special type of pods managed directly by the kubelet on each node ratherthan through the kubernetes API server.
Example: ApiServer, kube-scheduler, control manager, ETCD etc.

Labels and selectors:
Labels are key-value pairs used to tag and organize resources like pods, deployments and services. They help organize and group resources based on criteria that make sense to you.
Example for labels:
environment: production
type: backend
tier: frontend
application: my-app

Selectors filter kubernetes objects based on their labels. This is incredibly useful for querying and managing a subset of objects that meet specific criteria.

common usage:
pods: kubectl get pods --selector app=my-app
Deployments: used to filter the pods managed by the deployment.
Services: filter the pods to which the service routes traffic.

Kubelet:
- The kubelet is an agent that runs on each node in the cluster.
- It ensures containers are running in a Pod by communicating with the control plane.
- It watches for PodSpecs and reports node status back to the master.

configMap:
configMap allow you to externalize configuration from your container images. you can store key-value pairs(like application settings, DB URL's, feature flags etc) and then inject them into pod as 
- environment variables
- command line arguments
- mounted volumes(files)

In kubernetes, we have two types of resources which can be displayed using kubectl get api-resources
- namespace level(if NAMESPACED is true) 
- cluster level(if NAMESPACED is false)

steps to access persistent volume:
- install drivers
- give permissions to worker nodes(go to IAM role in workernode and add the access policy AmazonEBSCSIDriverPolicy)
- create volume
- create PV, PVC and claim through pod.
- EC2 and EBS volume should be in same AZ incase of EBS provisioning.

Storage class:
- this object is responsible for dynamic provisioning. it will create external storage and PV automatically.
this is achieved by below steps.
- install drivers
- give permissions to worker nodes(go to IAM role in workernode and add the access policy AmazonEBSCSIDriverPolicy)
- create storage class
k8s provides default storage class however we dont use it
kubectl get sc
default ReclaimPolicy: Delete , better use as Retain

EFS - Elastic File Sharing
- EBS should be in same AZ as in EC2, EFS can be anywhere in n/w.
- EBS speed is more compare to EFS.
- EBS is used for OS disk and databases. EFS can be used for file storages.
- EBS size is fixed. EFS will be scaled automatically.
- EFS is based on NFS protocol.
- EBS and EFS should be mounted to any instance.
- you can have any filesystem attached to EBS, but EFS use NFS. we cant change it.

EFS static:
- install drivers
- give permissions to worker nodes(go to IAM role in workernode and add the access policy AmazonEBSCSIDriverPolicy)
- create EFS
- open port 2049 on EFS to allow traffic from EC2 worker nodes.
- create PV, PVC and pod

EFS dynamic:
- install drivers
- create storage class
- give permissions

StatefulSets:
- Deployment is for stateless applications, generally frontend and backend.
- StatefulSet is for stateful applications usually databases.
- StatefulSet will have headless service, deployment will not have headless service.
- PV, PVS are mandatory for statefulSet.
- pods in statefulSet create in orderly manner with static names. ex: statefulset-0, statefulset-1 etc.

Headless service:
- A headless service in Kubernetes is defined with clusterIP: None and is typically used when you want the client to directly resolve and communicate with individual pod IPs. This is especially useful in StatefulSets where each pod needs a stable network identity for coordination, like in Cassandra or Kafka clusters.

Deployment:
when you hit nslookup on servicename, you will get ClusterIP as address.

you need to attach headless service to statefulset. why?
what is headless service? headless service will have no clusterIP. It will be attached to StatefulSet.

why statefulset have same names, pods preserve their identity?
nginx-0 delete, statefulset creates immediately another pod nginx-0 and it should attach to its own storage through naming convention. persistentvolumeclaim/www-nginx-0.

Deployment vs StatefulSet:
- Deployment is for stateless applications, generally frontend and backend.
- statefulset is for stateful applications usually database.
- statefulset will have headless service, deployment will not have headless service.
- PV and PVC are mandatory for statefulset.
- pods in statefulset create in orderly manner with static names. statefulset-0, statefulset-1 etc

Autoscaling:
- Vertical scaling: 2CPU, 4GB, 20GB HDD --> 4CPU, 8GB, 50GB HDD
- Horizontal scaling: create another server with 2CPU, 4GB, 20GB HDD and add to LB.

kubernetes resources:
---------------------
- Namespace
- Pod
- ConfigMap
- Secret
- ReplicaSet
- Deployment
- Service
- PV
- PVC
- StatefulSet
- HPA
- Headless service
- Helm Charts
- labels and selectors
- taints and tolerations
- affinity and anti-affinity
- ingress controller and Ingress resource


common errors in k8s:
- ErrImagePull - if node is not able to pull the image
- CrashLoopBackOff - container is unable to start
- Pending - worker node not available in that AZ, PVC is not bound to PV
- ContainerCreating - PV, PVC

Taints and Tolerations:
if you taint the node, scheduler will not schedule the pods on that node.
If you apply toleration on a pod, it will be scheduled with matching nodes.
Effects for taint:
------------------
- NoSchedule -> its like an order
- PreferNoSchedule -> its a request
- NoExecute -> existing pods also get evicted

NoSchedule: Prevents new pods from being scheduled.
NoExecute: Also evicts existing pods that don't tolerate the taint.

How to add a taint?
kubectl taint nodes node1 special=true:Noschedule
this prevents any pod from being scheduled on node1 unless it tolerates this taint

Example:
kubectl taint nodes node1 environment=prod:NoSchedule

Pod with toleration:
--------------------
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: nginx
    image: nginx
  tolerations:
  - key: "environment"
    operator: "Equal"
    value: "prod"
    effect: "NoSchedule"

this pod can run on the tainted node because it tolerates the environment=prod:NoSchedule taint

Remove a taint:
kubectl taint nodes node1 environment=prod:NoSchedule-

Taints applied at node level and tolerations applied at pod level.

Ingress resource:
-----------------
Ingress controller is used to provide external access to the applications running in kubernetes. we can set the routing rules through ingress resource either path based or host based. In EKS ingress resourcecan create ALB, Listener, Rule and target group. Ingress is attached to service, so it fetch the pods and add them to target group.

ServiceAccounts:
Service account is a non-human account, It is pod identity with which it can connect with api server and get access to external services.
when you create a namespace or every namespace will have default service account.
Service Account: default

Init Containers:
----------------
Init containers are used to setup the requirements for pod, for example backend pod can check whether database connections working fine or not.
Init Containers can fetch the secrets for pod before it starts.

InitContainers are special containers run before main container runs, we can use them to makesure dependent services are running fine before our main application starts and fetch the secrets from secret manager for main container. They always run to completion. you can run one or many init containers, they executed in sequence.

Init containers can do heavy lifting for main containers so that main container is less in size and limit attach surface of main container by not installing more tools in it

Kubernetes internal volumes:
emptyDir and hostPath
emptyDir -> pod temporary storage, accessible until pod lives. all containers in the pod can access init container. stores the secret in emptyDir and completes. then main container can access this.

DaemonSet:
Make sure pod replica runs on each node. monitoring purpose and logs collection, metric collection etc.

hostPath -> filesystem path in the underlying worker node. it is not secure, pods should not access host filesystems directly. But daemonset is only the exception for admins to collect logs and metrics.
